{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  # specify which GPU(s) to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import fastai\n",
    "# from fastai import ImageList\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks import SaveModelCallback\n",
    "#from sklearn.model_selection import KFold\n",
    "from utiles.radam import *\n",
    "from utiles.csvlogger import *\n",
    "from utiles.mishactivation import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this cell if run locally\n",
    "!mkdir './cache'\n",
    "!mkdir './cache/torch'\n",
    "!mkdir './cache/torch/checkpoints'\n",
    "torch.hub.DEFAULT_CACHE_DIR = 'cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sz = 128\n",
    "bs = 4\n",
    "nfolds = 2\n",
    "SEED = 2020\n",
    "N = 12 # number of tiles per image\n",
    "TRAIN = './input/panda-16x128x128-tiles-data/train/'\n",
    "LABELS = './input/prostate-cancer-grade-assessment/train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(LABELS).set_index('image_id') ## read in \"train.csv\" and set 'image_id' as index column\n",
    "files = sorted(set([p[:32] for p in os.listdir(TRAIN)])) ## extract image id from the img patch folder\n",
    "df = df.loc[files]\n",
    "df = df.reset_index() ## remove 'image_id' that without masks\n",
    "## stratified KFold class that can preserve the sample percentatage in each fold. \n",
    "splits = StratifiedKFold(n_splits=nfolds, random_state=SEED, shuffle=True) \n",
    "splits = list(splits.split(df,df.isup_grade)) ## list[(fold1_train_idx, fold1_test_idx), (fold2_train_idx, fold2_test_idx), ...]\n",
    "\n",
    "## mark each sample to the fold, in which the sample serve as a test case\n",
    "folds_splits = np.zeros(len(df)).astype(np.int) ## [0, 0, ...] with the number of cases\n",
    "for i in range(nfolds): \n",
    "    folds_splits[splits[i][1]] = i\n",
    "\n",
    "df['split'] = folds_splits ## add the K fold assignment column\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since I use zero padding and background corresponds to 255, I invert images as 255-img when load them. Therefore, the mean value is computed as '1 - mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\n",
    "std = torch.tensor([0.36357649, 0.49984502, 0.40477625])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(fn:PathOrStr, div:bool=True, convert_mode:str='RGB', cls:type=Image,\n",
    "        after_open:Callable=None)->Image:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n",
    "        x = PIL.Image.open(fn).convert(convert_mode)\n",
    "    if after_open: x = after_open(x)\n",
    "    x = pil2tensor(x,np.float32)\n",
    "    if div: x.div_(255)\n",
    "    return cls(1.0-x) #invert image for zero padding\n",
    "\n",
    "class MImage(ItemBase):\n",
    "    def __init__(self, imgs):\n",
    "        self.obj, self.data = \\\n",
    "          (imgs), [(imgs[i].data - mean[...,None,None])/std[...,None,None] for i in range(len(imgs))]\n",
    "    \n",
    "    def apply_tfms(self, tfms,*args, **kwargs):\n",
    "        for i in range(len(self.obj)):\n",
    "            self.obj[i] = self.obj[i].apply_tfms(tfms, *args, **kwargs)\n",
    "            self.data[i] = (self.obj[i].data - mean[...,None,None])/std[...,None,None]\n",
    "        return self\n",
    "    \n",
    "    def __repr__(self): return f'{self.__class__.__name__} {img.shape for img in self.obj}'\n",
    "    def to_one(self):\n",
    "        img = torch.stack(self.data,1)\n",
    "        img = img.view(3,-1,N,sz,sz).permute(0,1,3,2,4).contiguous().view(3,-1,sz*N)\n",
    "        return Image(1.0 - (mean[...,None,None]+img*std[...,None,None]))\n",
    "\n",
    "class MImageItemList(ImageList):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "    \n",
    "    def __len__(self)->int: return len(self.items) or 1 \n",
    "    \n",
    "    def get(self, i):\n",
    "        fn = Path(self.items[i])\n",
    "        fnames = [Path(str(fn)+'_'+str(i)+'.png')for i in range(N)]\n",
    "        imgs = [open_image(fname, convert_mode=self.convert_mode, after_open=self.after_open)\n",
    "               for fname in fnames]\n",
    "        return MImage(imgs)\n",
    "\n",
    "    def reconstruct(self, t):\n",
    "        return MImage([mean[...,None,None]+_t*std[...,None,None] for _t in t])\n",
    "    \n",
    "    def show_xys(self, xs, ys, figsize:Tuple[int,int]=(300,50), **kwargs):\n",
    "        rows = min(len(xs),8)\n",
    "        fig, axs = plt.subplots(rows,1,figsize=figsize)\n",
    "        for i, ax in enumerate(axs.flatten() if rows > 1 else [axs]):\n",
    "            xs[i].to_one().show(ax=ax, y=ys[i], **kwargs)\n",
    "        plt.tight_layout()\n",
    "        \n",
    "\n",
    "#collate function to combine multiple images into one tensor\n",
    "def MImage_collate(batch:ItemsList)->Tensor:\n",
    "    result = torch.utils.data.dataloader.default_collate(to_data(batch))\n",
    "    if isinstance(result[0],list):\n",
    "        result = [torch.stack(result[0],1),result[1]]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(fold=0):\n",
    "    result = MImageItemList.from_df(df, path='.', folder=TRAIN, cols='image_id') ## create a MImageItemList from pandas df\n",
    "    result = result.split_by_idx(df.index[df.split == fold].tolist()) ## split the data to train and val\n",
    "    result = result.label_from_df(cols=['isup_grade']) ## add label to the data\n",
    "    result = result.transform(get_transforms(flip_vert=True,max_rotate=15),size=sz,padding_mode='zeros') ## add transformation\n",
    "    ## flip_vert: limit the flips to horizontal flips (when False) or to horizontal and vertical flips as well as 90-degrees rotations (when True)\n",
    "    ## max_rotate: if not None, a random rotation between -max_rotate and max_rotate degrees is applied with probability p_affine (0/75)\n",
    "    result = result.databunch(bs=bs,num_workers=4) ## batch the data\n",
    "    return result\n",
    "\n",
    "data = get_data(0)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, arch='resnext50_32x4d_ssl', n=6, pre=True):\n",
    "        super().__init__()\n",
    "        m = torch.hub.load('facebookresearch/semi-supervised-ImageNet1K-models', arch)\n",
    "        self.enc = nn.Sequential(*list(m.children())[:-2])       \n",
    "        nc = list(m.children())[-1].in_features\n",
    "        self.head = nn.Sequential(AdaptiveConcatPool2d(),Flatten(),nn.Linear(2*nc,512),\n",
    "                            Mish(),nn.BatchNorm1d(512), nn.Dropout(0.5),nn.Linear(512,n))\n",
    "        \n",
    "    def forward(self, *x):\n",
    "        shape = x[0].shape\n",
    "        n = len(x)\n",
    "        x = torch.stack(x,1).view(-1,shape[1],shape[2],shape[3])\n",
    "        #x: bs*N x 3 x 128 x 128\n",
    "        x = self.enc(x)\n",
    "        #x: bs*N x C x 4 x 4\n",
    "        shape = x.shape\n",
    "        #concatenate the output for tiles into a single map\n",
    "        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous()\\\n",
    "          .view(-1,shape[1],shape[2]*n,shape[3])\n",
    "        #x: bs x C x N*4 x 4\n",
    "        x = self.head(x)\n",
    "        #x: bs x n\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'RNXT50'\n",
    "pred,target = [],[]\n",
    "for fold in range(nfolds):\n",
    "    data = get_data(fold)\n",
    "    model = Model()\n",
    "    learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), opt_func=Over9000, \n",
    "                metrics=[KappaScore(weights='quadratic')]).to_fp16()\n",
    "    logger = CSVLogger(learn, f'log_{fname}_{fold}')\n",
    "    learn.clip_grad = 1.0\n",
    "    learn.split([model.head])\n",
    "    learn.unfreeze()\n",
    "#     print(f'{fname}_{fold}.pth')\n",
    "    learn.fit_one_cycle(16, max_lr=1e-3, div_factor=100, pct_start=0.0)\n",
    "#       callbacks = [SaveModelCallback(learn,name=f'model',monitor='kappa_score')])\n",
    "#     torch.save(learn.model.state_dict(), f'{fname}_{fold}.pth')\n",
    "    \n",
    "#     learn.model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         for step, (x, y) in progress_bar(enumerate(data.dl(DatasetType.Valid)),\n",
    "#                                      total=len(data.dl(DatasetType.Valid))):\n",
    "#             p = learn.model(*x)\n",
    "#             pred.append(p.float().cpu())\n",
    "#             target.append(y.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = torch.argmax(torch.cat(pred,0),1)\n",
    "t = torch.cat(target)\n",
    "print(cohen_kappa_score(t,p,weights='quadratic'))\n",
    "print(confusion_matrix(t,p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
